% vim: tw=80 spell spelllang=en

\fontfam[lm]
\input ctustyle3
\load[vlna]
\singlechars{Czech}{AaIiVvOoUuSsZzKk}
\enlang
\enquotes
\verbchar`
\picdir={figures/}
\nonstopmode
\nonumcitations

\draft

\newcount \_secccnum
\def \_thesecccnum {\_othe\_chapnum.\_the\_secnum.\_the\_seccnum.\_the\_secccnum}

\_optdef\_seccc[]{\_trylabel \_scantoeol\_inseccc}

\_def\_inseccc #1{\_par \_sectionlevel=4
   \_def \_savedtitle {#1}% saved to .ref file
   \_ifnonum \_else {\_globaldefs=1 \_incr\_secccnum \_secccx}\_fi
   \_edef \_therefnum {\_ifnonum \_space \_else \_thesecccnum \_fi}%
   \_printseccc{\_scantextokens{#1}}%
   \_resetnonumnotoc
}
\public \seccc ;

\_def \_chapx {\_secx   \_secnum=0   \_lfnotenum=0 }
\_def \_secx  {\_seccx  \_seccnum=0  \_tnum=0 \_fnum=0 \_dnum=0 \_resetABCDE }
\_def \_seccx {\_secccx \_secccnum=0 }
\_def \_secccx {}


\_def\_printseccc#1{\_par
   \_abovetitle{\_penalty-100}{\_medskip}
   {\_bf \_noindent \_raggedright \_printrefnum[@\_quad]#1\_nbpar}%
   \_nobreak \_belowtitle{\_smallskip}%
   \_firstnoindent
}

\_def\secccfont{\_scalemain\_typoscale[\_magstephalf/\_magstephalf]\_ctustyle_boldify}
\_def\_printseccc#1{\_par \_abovetitle{\_goodbreak} 
  \_smallskip\_medskip\_vskip.5\_parskip
  \_ctustyle_begitemstest\seccc
  \_line{%\Blue\_vrule height 3.5mm width4mm depth.3mm\Black 
  \_hss\_vtop{\_advance\_hsize by-0mm
     \secccfont \_noindent \_printrefnum[@\_quad]%
     \_ctustyle_nBlue#1\_rightskip=0pt plus1fil \_strut\_nbpar\_kern-4.5pt}}%
  \_nobreak\_vskip-.5\_parskip\_smallskip\_vskip2pt\_relax
  \_firstnoindent
}


%\_sdef{_tocl:4}#1#2#3{\_advance\_leftskip by2\_iindent \_cs{_tocl:2}{#1}{#2}{#3}}

\newcount\tnotenum
\def\tnotelist{}
\def\tnote#1{\incr\tnotenum $^{\rm\_romannumeral\tnotenum}$\global\addto\tnotelist{{#1}}}
\def\tnoteprint{\par \tnotenum=0
   \ea\foreach\tnotelist
     \do{\advance\tnotenum by1 \par $^{\rm\_romannumeral\tnotenum}$##1 }\par
   \global\tnotenum=0 \gdef\tnotelist{}%
}

\def\pdfstdcite[#1]{[\rcite[iso32000-1], část~#1]}

\newdimen\halfhsize \halfhsize=\dimexpr\hsize/2-2pt\relax

\hyphenation{hon-or mark-up}

\_def\_urlskip{\_null\_nobreak\_hskip0pt plus0.1em\_relax}
\_def\_urlbskip{\_penalty50 \_hskip0pt plus0.1em\_relax}

\bibtexhook={
\_sdef{_print:misc}{%
   \_bprintb [!author]    {\_doauthor1{##1}\.\ }{\_bibwarning}%
   \_bprintb [title]      {{\_em##1}\_bprintc\_titlepost{\.\ *}\_bprintv[howpublished]{}{\.}\ }%
                                                                                     {\_bibwarning}%
   \_bprinta [howpublished]  {[*].\ }{}%
  %\_bprinta [ednote]     {\_prepareednote*\_bprintv[citedate]{}{.}\ }{\_bibwarning}%
   \_bprinta [ednote]     {\_prepareednote*\_bprintv[citedate]{}{.}\ }{}%
   \_bprintb [year]       {\_doyear{##1}\_bprintv[citedate]{}{.}\ }{\_bibwarninga}%
  %\_bprintb [year]       {\_doyear{##1}\_bprintv[citedate]{.}{.}\ }{\_bibwarninga}%
   \_bprinta [citedate]   {\_docitedate*///\_relax.\ }{}%
   \_bprintb [doi]        {\_predoi DOI \_ulink[http://dx.doi.org/##1]{##1}.\ }{}%
   \_bprintb [url]        {\_preurl\_url{##1}. }{}%
}
}

\def\optparams{\adef<##1>{\hbox{$\langle$\it##1\/$\rangle$}}}
\toksapp\everyintt{\optparams}
\toksapp\everytt{\typosize[9.5/12.4]}

\worktype [M/EN]

\faculty{F8}

\department{Department of Theoretical Computer Science}
\title  {x86-64 native backend for TinyC}
\titleCZ{x86-64 nativní backend pro TinyC}
\author{Michal Vlasák}
\date{XX.\,XX.\,TODO}
\supervisor{Ing. Petr Máj}
\abstractEN {
}

\abstractCZ {
}

\keywordsEN {%
TODO
}
\keywordsCZ {%
TODO
}
\thanks {% Use main language here
}

\declaration {
Prohlašuji, že jsem předloženou práci vypracoval samostatně a že jsem uvedl
veškeré použité informační zdroje v~souladu s~Metodickým pokynem o~dodržování
etických principů při přípravě vysokoškolských závěrečných prací.

Beru na vědomí, že se na moji práci vztahují práva a povinnosti vyplývající ze
zákona č.\,121/2000~Sb., autorského zákona, ve znění pozdějších předpisů.
V~souladu s~ust.\,§\,2373 odst.\,2 zákona č.\,89/2012~Sb., občanský zákoník, ve
znění pozdějších předpisů, tímto uděluji nevýhradní oprávnění (licenci) k~užití
této mojí práce, a to včetně všech počítačových programů, jež jsou její součástí
či přílohou a veškeré jejich dokumentace (dále souhrnně jen „Dílo“), a to všem
osobám, které si přejí Dílo užít. Tyto osoby jsou oprávněny Dílo užít jakýmkoli
způsobem, který nesnižuje hodnotu Díla a za jakýmkoli účelem (včetně užití
k~výdělečným účelům). Toto oprávnění je časově, teritoriálně i množstevně
neomezené.

V XX dne XX.\,XX.\,TODO
\signature
}

{\nopagenumbers
  {\pgbackground={
    \picwidth=\pagewidth \picheight=\pageheight
    \inspic{vlasami6-assignment.pdf}}
    \null\vfil\break}
  \null\vfil\break}
\makefront

\chap Introduction

\label[ragalloc]
\chap Register allocation

This chapter describes the last of the three big conceptual parts of a usual
compiler backend---the register allocation phase. Motivation, importance and
possible approaches are introduced.

The x86-64 architecture (see \cite[ref:x86]) is what we mainly care about in
this thesis. Since it is familiar, we will be using it as examples in the
following sections. It is also a good candidate because it brings some
challenges not found on other architectures, but shows the general problems just
as well as other architectures.

Note that like with instruction selection although we are already working with
target specific instructions, their form doesn't necessarily have to be target
specific. Target independent representation of target specific instructions
allows us to share also register allocation logic for all targets.

\sec Motivation

Most CPU architectures these days are register based. That means that interface
of the CPU consists of a fixed number of registers and instructions that allow
operations on these registers. For example registers may be 8 32-bit storage slots
and instructions may allow performing arithmetic on these registers or allow
loading/storing contents of register from/into memory. Memory is still an
important part of these architectures---computations can't possibly fit all into
a fixed number of registers of fixed size, it is the memory that allows us to
store large amounts of data.

During previous phases of the compiler we used a powerful abstraction, we
pretended that there is an infinite amount of registers. This is very important
for the middle end IR, since it is supposed to be platform agnostic and rather
than limiting to some fixed number of registers (per architecture or wholesale),
we might as well pretend to have infinite amount of them. But once we start
translating the middle end IR we just need to limit ourselves to fixed amount of
registers somewhere. And not only that architectures these days usually have at
least two classes of registers---general purpose registers and floating point
registers...

After instruction selection (which tells us what instructions to use) and
instruction scheduling (which refines the order these instructions are executed
in), a snippet of input to register allocation can look as follows:

\begtt
mov t1, 1
mov t2, 2
mov t3, t1
add t3, t2
\endtt

There are several things of note here. The instructions don't operate on real
machine registers (like `rax`), but on "virtual registers" or "temporaries". It
is the goal of register allocation to transform the code so that real registers
are used. The snippet corresponds to this middle end IR:

\begtt
v1 = add 1, 2
\endtt

The translation given above is suboptimal and in a reasonable compiler such code
wouldn't get as far as to the register allocator: the middle end could fold the
addition of constants into a constant, or the instruction selector could take at
least take advantage of "register plus immediate" instruction for addition.
Nonetheless the example serves us well for showing how a simple allocation of
registers might look like. Since the whole program doesn't use more than 16
registers, we have no problem assigning x86-64 registers directly, for example
in the order of the temporaries:

\begtt
mov rax, 1   // t1 = rax
mov rbx, 2   // t2 = rbx
mov rcx, rax // t3 = rcx
add rcx, rbx
\endtt

Even for such a simple example, we can notice several things about register
allocation alone:

\begitems
 * We introduce a third register `rcx` to store the result of addition. This
works well and fits into the 16 registers we have available. But we can notice
that after the addition we no longer need the value stored in register `rax`.
Thes is the core idea of register allocation, we only need to store such values
that will be needed in the future, and contrary to SSA we can use that to
"recycle" registers.

* If we were to reuse `rax` for storing the result of addition, our situation
would look like this:

\begtt
mov rax, 1   // t1 = rax
mov rbx, 2   // t2 = rbx
mov rax, rax // t3 = rax
add rax, rbx
\endtt

Move (copy) of a register to itself is a no op, the instructions doesn't have
any real effect (other than settings flags TODO). But at least in this case it
is safely possible to remove that instruction. We can notice that the "two
address code" generated from SSA "three address code" can be improved if it
turns out that the destination can be the same register as the first source (or
the second source in this case, since addition is commutative).

But a question remains, can the register allocator remove the instruction?
Or should it even? + Spill insertion.
\enditems

As we have seen, opportunities often arise for register reuse. Then what are the
situations where we can get out of registers? Well, when we can't get away with
reuse. We should consider the difference between (naive, but illustrative)
compilation of expression `1 + 2 + 3 + 4` and its possible register allocation:

\begtt
mov t1, 1  // t1 = rax
mov t2, 2  // t2 = rbx
mov t3, t1 // t3 = rax
add t3, t2

mov t4, 3  // t4 = rbx
mov t5, t3 // t5 = rax
add t5, t4

mov t6, 4  // t6 = rbx
mov t7, t3 // t7 = rax
add t7, t5
\endtt

And as opposed to that the "right associative" version: `1 + (2 + (3 + 4))`

\begtt
mov t1, 1  // t1 = rax
mov t2, 2  // t2 = rbx
mov t3, 3  // t3 = rcx
mov t4, 4  // t4 = rdx

mov t5, t3 // t5 = rcx
add t5, t4

mov t6, t2 // t6 = rbx
add t6, t5

mov t7, t1 // t7 = rax
add t7, t6
\endtt

Even though both versions use the same amount of {\em virtual registers}, their
opportunities to reuse registers and hence use of {\em physical registers}
differs considerably. While the example is trivial and the right associative
version could be transformed into the left associative version the highlighted
issue here is, that even single benign expressions can use a surprising number of
registers. Just extending the addition to more than 16 addends would leave us
out of registers. So not only for variables (which for example in C nominally
reside in memory), but even for temporaries we have to account for the fact that
we simply can get out of registers.

\label[sec:spilling]
\sec Spilling

We can get out of registers, but we still have to store our (say intermediate)
values {\em somewhere}. The solution is to put the values into memory. Resorting
to putting the values to memory is called \"spilling".
The system stack (\"frame stack", \"call stack") is best suited for spilled
values, much for the same reasons it is the best place for storing local
variables: recursion is handled naturally and well, since each {\em invocation}
of a function gets its own locations for storing the values---by storing the
values on the stack, we allow functions to be {\em reentrant}.

Architectures usually also have a dedicated register for the pointer to \"the
top of the stack", which means that code needing to access the values not
fitting into registers can address their memory locations using relative
addressing with small offsets (say smaller than 16 bits), also a feature
efficiently supported by all common architectures these days. On the other hand
accessing static slots of memory would pose similar challenges as global
variables have - they may not be reachable with small relative offsets from any
register and especially on 64 bits systems their absolute address is not only too large
to be stored in literals in code, but using absolute addresses is also
discouraged, because it means that the code becomes {\em position
dependent}---change of the absolute address through a change in position in
address space, would mean that our code would no longer be correct. Such
absolute references require run time fix ups (called \"relocations") by the
dynamic linker, which prevents reuse of the code between multiple processes.

\label[sec:use-of-spilled]
\secc Using spilled values

As established, we will refer to spilled values through relative addressing
(using either the stack pointer or the \"base" pointer, also often called the
\"frame pointer", see TODO). But we have to get back to the problem at
hand---we store values in registers, because we want to use the values in
computations and processors (mostly) operate on registers. But now that we can't
fit all values into registers and want to store them in memory, how do we use
the values from memory and how do they even get there?

RISC processors usually employ a \"load-store" architecture. There are only a
few dedicated instructions for reading values from memory into registers (`load`
instructions) and writing register contents into memory (`store` instructions).
All other instructions operate only with registers. This means that to even have
a value to spill, it has to be in a register! Also only from that register, we
can store the value to memory and later retrieve it, but again only into a
register. The important observation here is, that resorting to storing the
values in memory doesn't in general mean that we get around of doing register
allocation. What we gain is that instead of having to store a value in a
register in a long part of the code (because it is needed in all parts of that
code), by putting the value into memory and retrieving it immediately before
each use, we have made the register allocation problem simpler---a register is
needed in more but smaller parts of the code. This means that a single machine
register can be reused for several values, instead of being blocked by "one".

At least the register used for the store, doesn't have to be the same one used
for the load. So even though we are constrained by the fact that registers have
to be used for spills, we are not too constrained in choosing the registers for
performing spills. Loads and stores inserted for handling spills are usually
called the {\em spill code}.

In this text, we care especially about the x86-64 architecture, which, like most
CISC architectures, doesn't have a load-store architecture. There are
instructions which can e.g. perform arithmetic directly on locations in memory.
Though at most one operand of an instruction can be a location in memory, the
other one has to be either a register or an immediate value. So on one hand, the
problem of having to use {\em registers} for storing/retrieving
spilled values remains, but on the other hand, since one operand can be a
location in memory, we can take advantage of that and not use an intermediate
register at all.

An interesting perspective is, that even though the x86-64 architecture allows
the instructions to operate on memory operands, an implementation of the
architecture in for example some new Intel processors splits these instructions
into micro-operations based on the load-store architecture, using some internal
\"architectural" registers (not normally accessible directly) for storing the
intermediate values. Because of this there probably isn't any {\em direct}
performance difference of using the memory operands. But it is still very useful
to use these more complex instructions---not only can the instruction encoding
be shorter (thus sparing the instruction cache of the processor), but we take
advantage of the internal architectural registers, that we normally wouldn't
have access to, which can mean less constraints on the use of the ordinary
\"general purpose" registers that we have access to, which may allow storing
more values into registers instead of memory and hence have a significant {\em
indirect impact} on performance.

For example, let's say that `t4` needs to be spilled in the following:

\begtt
add t3, t2
\endtt

Instead of adding a load before the instruction of `t4` and a store of `t4`
after, like this:

\begtt
mov t4, [rbp+t3]
add t4, t2
mov [rbp+t3], t4
\endtt

We can just operate on the memory location:

\begtt
add [rbp+t3], t4
\endtt

This example also showed, that as mentioned, at least with a very narrow local
view, and with the first simpler solution, spilling `t3` doesn't help with the
use of registers! We needed to introduce another pseudoregister, `t4`, to hold
the value of `t3` loaded from memory. Indeed, spilling helps only in a broader
scope, where splitting definitions / uses of one pseudoregister into single
definitions and singe uses of many different pseudoregisters help making the
register allocation solvable (due to limited number of registers) or easier.

Thus for spills, we want to introduce a new temporary for each new load and
store, but that is not the case in the example, `t4` is used also for storing
spilled `t3` back to memory. This is needed, since as we have discussed in TODO,
most instructions on the x86-64 use the "two address code", where one of the
operands is also the destination for the result. So it is not directly possible
to store the result in a different location than the location of the first
operand. Judging the snippet only locally, the transformation is fine, since the
`original` value of `t3` was also \"destroyed" in the original version. In
general, the original value of `t3`, before the addition, {\em might} be needed
even after the addition. That is why the code generator might need to output the
following sequence to add `t1` and `t2` into `t3` while preserving all of `t1`,
`t2` and `t3`:

\begtt
mov t3, t1
add t3, t2
\endtt

Now the prospect of naively spilling `t3` seems even worse:

\begtt
mov [rbp+t3], t1
mov t4, [rbp+t3]
add t4, t2
mov [rbp+t3], t4
\endtt

The code generator hoped that by assigning `t1` and `t3` the same register, the
move instruction could be eliminated. Since for some reason `t3` was spilled,
that is now out of the question, but there is still a suboptimality---`t1` is
copied to memory and then immediately loaded back again into `t4`, because it
needs to be used in the `add` instruction and then also stored back into memory.
Use of `t3`'s memory location as the first operand of the `add` instruction
helps as before:

\begtt
mov [rbp+t3], t1
add [rbp+t3], t2
\endtt

But in some sense, this is a red herring---the memory operations are still
there, the CPU still has to load the value `t3` from memory in the `add`
instruction, when we just had it in a register. Just because the addressing
modes of x86 allow use of memory locations in the instruction encodings, doesn't
mean that internally the ALU (Arithmetical logical unit) can suddenly operate
directly on memory, the CPU still has to internally load the value into a
register. So while we spare a general purpose register and instead use an
architectural one, we still excessively operate on memory. Alternatively instead of
using memory location for the `add` instruction we could move the value from
`t1` directly into memory, because store/load pair didn't have any meaning at
all---we store the result of addition to `t3` in the last instruction after all.

\begtt
mov t4, t1
add t4, t2
mov [rbp+t3], t4
\endtt

Now, we keep the values in registers the whole time, and only store the final
result in memory on assumption that later the value is needed and storing it in
memory somehow helps the register allocator. While the first example is two
instructions, it is X bytes, while the second one is 3 instructions and Y bytes
TODO: compare lengths of instructions. But in fact this is how we started in the
first place---just have the values in the registers. The important difference
is, that the register `t4` introduced by spilling, is a temporary, it's value
ends right at the store to `t3`'s location in memory. Thus it makes the register
allocation problem much easier than previously just with `t3`. For example now
it is even more likely that `t4` and `t1` are assigned the same register, thus
making the first instruction a noop. The reason why it is easier to merge with
`t4` instead of `t3` is not really apparent from this local view, but we have
TODO less interference.

Another point of view on the issue is, that essentially, in (the last snippet)
in the first two instructions `t3` is represented by `t4`, while in the last
instruction it shifts from being represented by `t4` to be represented by `t3`,
which due to some previous decision, resides in a memory location. We have
essentially split the register `t3` into multiple registers connected by moves
and it improved the generated code. In contrast, we argued, that by merging `t4`
and `t1` we would have had the chance to eliminate the move instruction, thus
improving the code as well. Both "merging" (also called {\em coalescing}), and
\"splitting" can both improve the code in different situations, this makes it
even harder, because recklessly doing one or the other will make the code
certainly worse, while doing neither may as adding these contrasting notions
makes great register allocation an even harder problem.

\secc Interaction with instruction selection

As we have seen, the process of spilling needs to insert new instructions which
together form the so called "spill code". In simplest scenario they just load
and store the value, but better code can be achieved if the spill code is
inserted with better thought than just load from memory and move to memory. But
both of these problems---selecting the instructions to use for operations and
additionally making nontrivial transformations based on the code at hand was
exactly the job of instruction selection.

In principle, register allocator shouldn't care about the instructions. It
should only cares about their effects on the registers. The result of register
allocation should be the assignment of register to pseudoregisters. Since spills
can be necessary, which requires insertion of new instructions, we have to
decide how this spill code will be handled. The basic options are the following,
and mostly depend on the chosen register allocation technique:

\begitems
* Insert spill code in the register allocator pass.
* Return the list of spilled pseudoregisters, and expect to be called again with
code transformed to include the spill code.
\enditems

The first option can make the register allocator depend on the target
architecture---it now needs to know about the current target, its instructions,
their meanings and how to insert them. On the other hand, register allocation is
already in the "backend", where we expect to handle things on the level of the
target, and generally hope to take advantage of that by, for example, doing
optimizations specific to the particular target. This can be application of that
idea. On the other hand, as mentioned previously, machine independent
representations of machine dependent instructions are possible, thus spill code
insertion {\em could} also be made machine independent similarly as instruction
selection.

The second makes the register allocation process pure in a sense. The register
allocator never modifies the input, its result is a either a mapping of
pseudoregisters to registers, or a list of pseudoregisters to be spilled.
Though it still has to be decided on how to insert the instructions. Some
instruction selection mechanisms which ultimately depend on the middle end IR,
are not suitable for inserting and optimizing spill code, since we are already
in the "low level" backend IR. Tree or DAG based instruction selection
mechanisms may also not be directly applicable---we may no longer be using
trees or DAGs for representing the machine code, especially after instruction
scheduling, which sets the order of instructions in stone. On the other hand
peephole optimization is a great fit for improving inserted spill code. The
inserted spill code can be very naive, and peephole optimization run on the
spill code and its surroundings can make improvements. This is especially likely
if we are able to find patterns which spilled code creates, such as in the
example in the previous subsection (\ref[sec:use-of-spilled]).

The obvious downside of the \"pure register allocation" approach is, that it has
to start over with register allocation, if any spills need to be made. The first
approach seems more suited to register allocation where we would want self
contained and final results in possibly just one pass. The approaches used for
spill code insertion are usually very connected to the core principle of the
register allocation algorithm at handle, and choices of some approaches are
discussed in the section~\ref[sec:regalloc-techniques].

\sec Formalization

The terms used in the previous sections about register allocation were not
properly defined, and perhaps even not commonly used for the concepts. The
intention was to practically show the problems register allocation tries to
solve and what needs to do to solve it, which of course includes optimizations
that try to make the register allocation process more optimal.

One thing that has to be noted is the name \"register allocation" itself. We
in fact mentioned that register allocation is meant to map pseudoregisters to
real machine registers of the target architecture, but the process isn't always
so direct, and sometimes it makes sense and brings benefits to split this
process into two parts, which really define what we mean by these names:

\begitems\style n
* {\em Register allocation}. In a narrower sense, by register allocation we mean
the process of making sure that each pseudoregister can be assigned a register.
At this point, we may not care too much about which one, but we care about spill
code, because that is what allows us to fit into the limited amount of registers
available.
* {\em Register assignment}. The assignments follows allocation---now that we
can map every pseudoregister left into at least one register, we choose the
concrete one. Although this seems much more simpler than the allocation part,
in practice register assignment is also very important, because we have seen
situations where some assignments lead to better code, for example where the
source and destination of a move instruction are assigned the same register, the
move instruction can be eliminated.
\enditems

Some register allocation algorithms intertwine both parts and don't split them.
Some algorithms strictly separate these concerns. In general simpler algorithms
usually merge both of these parts, while more complex algorithms try to take
advantage of the attacking each of those issues separately to reach more optimal
results. But this distinction is of course not definitive.

\secc Liveness, inteference

\secc Live ranges

vs value vs variable.

\secc Coalescing

\secc Live range splitting

\label[sec:regalloc-techniques]
\sec Techniques

We have already seen a few things that can distinguish different register
allocation algorithms:

\begitems
* Handling of spilling (section~\ref[ref:use-of-spilled]),
* Split or no split of allocation and assignment
(section~\ref[ref:regalloc-formalization]).
\enditems

\noindent But there are others:

\begitems
* Scope: {\em local} vs {\em global} vs {\em interprocedural} vs {\em whole
program} algorithms. Local algorithms operate on singular basic blocks and use
only information local to the basic block to decide on register allocation. The
limited scope makes the algorithms generally simpler and produces worse results
then global register allocation, which allocates registers to whole functions.
Global register allocation is global in the sense that {\em all} basic blocks
are considered at the same time. The analysis is more complex, since it has to
handle control flow. Even techniques for allocating registers across function
calls and whole programs exist. These can be less practical in practice, where
functions may be required to conform to a {\em calling convention}, which
specifies how arguments should be passed in function calls, what registers are
preserved by calls and where will the return values reside. We will not discuss
techniques operating in larger scopes than {\em global} (whole function, all
basic blocks).

* {\em Quality} vs {\em speed}. With no restrictions on time, we ideally would
like to achieve {\em optimal} register allocation. With the right definition of
optimal, it can be possible, but due to the difficulty of the register
allocation, this approach is bound to be too slow (in {\em compile-time}),
although it would produce code that would be fast (in {\em run-time}). In code
compiled ahead of time, we can probably justify spending more time on
compilation to achieve better run-time, since it is expected, that the program
will run for some time and that the investment will return.

On the other end of the spectre we may want a register allocation algorithm that
runs very fast (due to constraints on compile-time), but in that case we can't
expect good results (i.e. code that has fast run-time). This can be interesting
for {\em Just-in-time} (JIT) compilers, where the compile time is part of
run-time and hence it is not possible to spend much time on optimizations,
because it is possible that they wouldn't pay off (though they could, we don't
know ahead of time).

* {\em Control flow sensitivity}. Some global algorithms may completely
disregard the actual control flow of the program and just use (global) liveness
and/or interferences to do register allocation and assignment. But use of
control flow information in an algorithm is likely to steer it to better
results---spills in hot or nested loops are undesirable. Control flow sensitive
register allocation (not assignment) may for example even try to purposefully do
spills before loops to make more registers available in loops.

\enditems

\label[sec:regalloc-top-down]
\secc Top-down, bottom-up

\secc Backward

\secc Linear scan

\secc Graph coloring

Even though the idea of using graph coloring for register allocation is older,
first notable use of the technique is by Chaitin~\cite[Chaitin1981, Chaitin1982].
The core of the idea is to construct an interference graph from the
interferences of virtual registers---all virtual registers become nodes in a
graph and there is an edge between virtual registers if and only if they
interfere. Then on this graph we aim to find a {\em coloring}---mapping of nodes
to colors, such that no neighbouring nodes get the same color. In our case the
colors ultimately constitute the machine registers. Because edges designate
interference, it is guaranteed that no virtual registers that interfere are
assigned the same physical register. If we have $k$ machine registers available,
then we are looking for a $k$ coloring---the coloring needs to use at most $k$
colors (registers).

By reducing the register allocation to graph coloring we may seemingly not
gain much, since graph coloring is an NP-complete
problem\fnote{In~\cite[Chaitin1981] authors argue further that register
allocation is also NP-complete, this has since been
disputed~\cite[Bouchez2007].}. However in~\cite[Chaitin1981] they rediscover a
technique that can simplify and make graph coloring practical for register
allocation. It is based on the observation that a node which has fewer than $k$
neighbours can be always assigned a color distinct from all of its neighbours.
Because the node has less neighbours than there are available colors, even if
all neighbours used different colors, there would still be a free color left.
This simple, yet important observation is the base for their and derived
techniques.

Since incorporating a node with degree (number of adjacent nodes) less than $k$
(a so called {\em insignificant}
node) into an already colored graph is easy, initially we do the
opposite---remove from the graph all insignificant nodes, such that later, in
the reverse process we can add them back to the graph and color them trivially.
Removing low degree nodes from the graph causes the degrees of neighbouring
nodes to decrease as well and may thus lead to more simplifications. In
Chaitin's algorithm this phase is called {\em simplify} and the
removed low degree nodes are pushed onto a stack. In the final stage, called {\em
assign}, the nodes have colors assigned in the reverse order simply by popping
them from the stack and assigning them a color not used by any of the already
colored neighbours in the now being rebuilt graph. Use of this heuristic is not
all saving---it is possible that after after simplification (removal of low
degree nodes) there will still be high degree nodes left. In that moment, push
of any of the remaining nodes on to the stack, could mean that there won't be a
color left for it. Chaitin's solution is to calculate spill costs of all the
remaining high degree nodes, choose the one with the lowest cost, mark it as
to be spilled and remove it from the graph. Due to the removal, the
simplification process may find more simplifications, otherwise another spill
decisions may be made. The removal of the to be spilled node from the graph
simulates its replacement by loads and stores, which although will introduce new
virtual registers, they will have very short live ranges, with (hopefully) much
less interferences, so it suffices as an approximation.

Spill of any node means that the code needs to be updated with spill code, and
the register allocation process repeated. Since the program is now different,
and new pseudoregisters were introduced to accommodate spill code,
liveness analysis and building of interference graph have to be repeated as
well. Then simplification can be tried again. This entire process is tried
until the simplification is able to reduce the graph to an empty graph, which is
trivially colorable. Since each iteration is very expensive, it is important
that there can be multiple spill decisions made in a single {\em simplify} run,
this way the process can often finish in 1 or 2 iterations, if the first
iteration successfully finds all nodes that need to be spilled and the second
iteration finalizes the assignment.
Being able to spill only one node on each iteration would mean that graphs with
many high degree nodes would need {\em many} expensive iterations to finish.
Proceeding from {\em simplify} only after all spill have been handled makes it
possible to push only low degree nodes, guarantees that in the reverse {\em
assign} stage, every node popped from top of the stack will have at least one
free color.

But, it is possible to do better. The fact, that a node has a {\em significant}
number of neighbours doesn't mean, that it will be uncolorable in the {\em
assignment} stage. There is a chance that the already colored neighbours will be
assigned less than $k$ distinct colors (TODO: figure), in that case the popped
node could still be colored even though at the time it was pushed it was
significant. Because of this, in {\em simplify} we may optimistically try to
remove and push high degree nodes on to the stack, instead of pessimistically
spilling them. If in the assignment phase it turns out that there isn't a color
left for the popped node, we spill it only then. We call these pushed high
degree nodes {\em potential spills}, since they become {\em actual spills}
spilled in the {\em assign} stage. This strategy is called {\em optimistic
coloring} and was devised by Briggs~\cite[Briggs1992, Briggs1994]. Even in this
strategy, it can happen that more than one (potential) spill will be necessary.
Like with Chaitin's \"pessimistic" spilling, that the best possible node as
potential spill is the one with the lowest spill cost---first potential spill
will be processed last in the {\em assign} stage, and will encounter a more
complete interference graph, than potential spills pushed later, which are
assigned colors earlier. Like before, we want to capture all {\em actual}
spills, before we repeat the whole process with spill code inserted. To do this,
in the {\em assignment} stage we don't allocate the actual spills any color,
just mark them for spilling and proceed. This can make more some nodes
neighbours of actual spills colorable, since by not coloring the actual spill,
they effectively have one less interfering node. Like with Chaitin's spilling in
{\em simplify} stage, this approximates the actual effect of spilling, which
splits a single node into many temporaries whose interferences are more local
and hopefully easier to deal with.

As we have seen before (in section~\ref[sec:spilling]), spilling can always be
necessary, reducing the register allocation problem to graph coloring doesn't
change that. No matter how $k$ is big, there are always graphs which need more
registers to be colored successfully. Even an exact graph coloring algorithm
that tries all possibilities can fail to find coloring because of this. Spilling
is thus {\em not} only due to Chaitin's heuristic. Though the heuristic even
with Briggs' optimistic coloring can introduce more spills than a more exact
algorithm would.

The interference graph is a really great data structure, because apart from
being able to represent the \"live at the same time, and thus unallocatable to
the same register" constraints, it can express also other restrictions. Machine
constraints (instructions working with only some registers) and calling
conventions, which both restrict uses of {\em physical} registers, can be
modelled by interferences (edges in the interference graph) if we also add
physical registers as nodes. For example, we can force a virtual register node
to be allocated to a particular physical register by making it interfere with
nodes corresponding to all the other physical registers. This is often called
"precoloring". In fact, since we need to be careful about not accidentally
allocating physical register a different physical register, we make all physical
registers interfere with each other, this way they are all guaranteed to be
allocated their one color (register). But these additional constrains can lead
to uncolorable (\"overconstrained") graphs if the live ranges of precolored
registers are too long.

For example on the x86-64 architecture shift instructions expect the shift size
to be specified by either an immediate value or by the `cl` register. Having
more than one shift instruction in one function can lead to uncolorable graph,
if the precolored nodes interfere like in is the case below with `t2` and `t4`:

\begtt
sal t1, t2 // precolor t2 to cl
sar t3, t4 // precolor t4 to cl
\endtt

Problem would occur in the {\em assignment} stage, where one of `t2` or `t4`
would be assigned the `cl` register (since it interferes with all other physical
registers), but the other of the two virtual registers would have no register
left, since the only suitable register `cl` is occupied by a neighbour in the
interference graph (an interfering virtual register, live at the same time).
Spilling can save the situation, for example spill of `t4` helps if `t2` isn't
needed after this snippet of code:

\begtt
sal t1, t2 // precolor t2 to cl
mov t6, [rbp+t4]
sar t3, t5 // precolor t5 to cl
\endtt

Spilling both of course also helps, but spill of `t2` alone doesn't, because the
newly introduced temporary `t5` (precolored to `cl`) is still alive at the same
as `t4` and thus interferes:

\begtt
mov t5, [rbp+t2]
sal t1, t5 // precolor t5 to cl
sar t3, t4 // precolor t4 to cl
\endtt

The problem with spilling here is, that the spilling decisions {\em usually}
don't do that deep analysis to realize that spilling `t4` might make the graph
colorable. The usual spill heuristics are based on the degree of the nodes
(spilling nodes with high degree will decrease degrees of another nodes and thus
simplify their allocation) and expensiveness of the spill (i.e. the cost of the
load and store memory operations that would need to be introduced). But `t2` and
`t4` may not be good spill candidates according to this metric. Spilling them
helps, but if it occurs too late, it is possible that a lot of the other nodes
would already be spilled first. An alternative approach based on {\em live range
splitting} is what is much better at keeping local the effects of interferences
introduced by machine or calling convention constraints. Splitting introduces a
{\em copy} into a new virtual register for each constrained use as well as
definition. These new temporaries can be precolored, since their live ranges are
too short to interfere with each other. For instance, in the previous example,
it would look like this:

\begtt
mov t5, t2
sal t1, t5 // precolor t5 to cl
mov t6, t4
sar t3, t6 // precolor t6 to cl
\endtt

Temporaries `t5` and `t6` don't interfere. If, like we assumed earlier, `t2`
doesn't {\em live out}, then the best assignment would assign `t5` the `cl`
(`rcx`) register as well, and the code after allocation could look like this:

\begtt
mov rcx, rcx
sal rax, cl
mov rcx, rdx
sar rbx, cl
\endtt

Here it was possible to keep all values in registers. The first copy can be
easily optimized by subsequent peephole optimization pass.

Register allocation by graph coloring is thus very powerful and flexible with
regards to at least the machine and calling convention constraints presented
here. But avoiding uncolorable graphs with splits means a lot of copy
instructions, which if allocated different registers, will not be optimized by
peephole optimization and thus can incur significant unnecessary overhead. We
described (in section TODO) that coalescing is the name of the technique that
tries to allocate the target and source into the same register. Chaitin already
realized the need for coalescing. His solution~\cite[Chaitin1991] was to
coalesce every {\em copy-related}, {\em non-interfering} pair of virtual
registers in a pass called {\em coalesce}, before simplification. A pair of
virtual registers `t1` and `t2` is copy related when there is a copy (move)
instruction between them (i.e. `mov t1, t2` or vice versa), which captures the
goal of eliminating these moves. The virtual registers have to be
non-interfering, since otherwise the coalesced node would be uncolorable, and
also, since the temporaries interfere, and would be assigned distinct colors,
elimination of the copy wouldn't be possible anyways. Because of the
non-intefering criterion, we have to be careful not to create artificial
interferences for the operands of a copy instruction, for example `mov t2, t1`
alone shouldn't imply that `t1` and `t2` interfere! Chaitin essentially does
coalescing everywhere where it is possible and where it {\em might} be
beneficial. Because of its nature, this form of coalescing has later become
called \"aggressive". The problem with it, is that the node created by
coalescing two virtual registers has interferences of both of the former nodes,
notably this means that the node's degree will be the sum of the two degrees and
such nodes easily become significant (\"high degree", not trivially colorable).
High degree nodes are problematic in the following {\em simplify} phase, because
apart from being blocked from simplification themselves, they prevent
simplifications on a high number of other nodes. Often this means spills of
these high degree nodes. Aggressive coloring can make colorable graphs
uncolorable, and depends on spilling to make the graph colorable again. But,
since a spill of a node essentially splits the node into many low degree nodes,
this effectively undoes coalescing, but also adds memory operations that weren't
there originally.

Briggs improved on this by employing so called {\em conservative coalescing}.
Instead of coalescing all nodes that can be coalesced, he uses a filtering
heuristic, which allows only those coalesces, that can't make the graph
uncolorable. The filtering is done using a heuristic, because exactly predicting
the effect on colorability is a hard problem and would be too time consuming.
Since the effect of aggressive coalescing can be so severe, the heuristic was
made conservative, i.e. it never allows coalescings which would make the graph
uncolorable, but may also not allow coalesces that would be perfectly fine.

Appel and George found that for their use aggressive coalescing produced too
many spills, while conservative coalescing was too conservative, i.e. there were
are too many uneliminated move instructions left, even though coalescing would
be fine. They suggest an improvement called {\em iterated register coalescing}.
The idea is to still use only Briggs' conservative coalescing (to prevent making
the graph uncolorable), but instead of doing all the coalescing upfront, they
iterate the simplify and coalesce phases repeatedly. What is important is, that
simplify precedes coalescing---this alone improves the coalescing phase a lot,
since the conservative heuristic is based on degrees of nodes, and
simplification can decrease them significantly. But importantly after coalescing
there may be nodes which become insignificant. For example, if `t3` interferes
with both `t1` and `t2`, and the two are coalesced into `t12`, then in effect
`t3` loses a neighbour and it's degree is decreased, and it might just become
insignificant (\"low degree") and simplifiable (leading to more simplifications,
which in turn might lead to more coalescings, etc.). While this may seem like a
perfect positive feedback loop, it is important to recall from TODO ref, that
coalescing two nodes creates a node of higher (even significant) degree.

Park and Moon note that even iterated coalescing can be too conservative and not
combine nodes that could be safely combined. They also note that that the
positive effect of coalescing explained in the previous paragraph is not to be
underestimated. Their approach is called {\em optimistic
coalescing}~\ref[Park2004], not to be confused with {\em optimistic coloring}
due to Briggs~\ref[Briggs1992].
%Though the optimistic idea {\em is}
%similar to Briggs's improvement to coloring, where he realized that performing
%spills in the {\em simplify} stage is premature, since the {\em assign} stage
%might be able to assign register after all, but if it isn't able to, only then
%an actual spill is made.
Park and Moon's idea is to do aggressive coalescing like Chaitin did, to exploit the
positive effect of coalescing, but their improvement lies in being able to
revert coalescing of a particular node, if it would have to be spilled. Briggs'
optimistic coloring delayed actual spilling until the {\em assign} phase, since by
then it may turn out that the concrete assignment isn't as unfavorable as it
could have be just by judging from the interference graph and the simplification
heuristic. Similarly Park and Moon moves decisions to {\em not coalesce} into
the {\em assign} stage, and they are able to do better just because the concrete
assignment is known. For example, in case a color is not available for `t12`
(the result of coalescing `t1` and `t2`), it may be possible to find a color for
`t1` or `t2` (or both, though it will not be the same color), which effectively
undoes the coalescing. Though in practice, while Briggs' optimistic coloring
improvement was simple addition and a sure improvement, optimistic coalescing
and especially an efficient implementation is not simple.


\rfc{Chaitin coalescing, Briggs coalescing, iterated coalescing}


Nice thing about Chaitin's scheme (and Briggs' improvement) is that even the
introduced spill code with new virtual registers gets the same general treatment
as other virtual registers - they are allocated by the next iteration of graph
coloring, so although the spill code needs to be inserted separately, it is
{\em not handled specially}. The price for this is that multiple expensive
iterations may be needed to finalize the allocation. An alternative would be to
(like with the top down allocator in section~\ref[sec:regalloc-top-down])
reserve a few registers off the side and use them to perform the loads and
stores around spilled variables. This could be used to rewrite the program into
final form after just one iteration of the graph coloring register allocator.
While this potentially saves multiple expensive iterations, it is less
flexible than coloring the spill code in a new iteration. In particular, since
the few spill handling registers have to be set off the side for the whole
program, we are not able to assign them, so in fact we are looking for a $k$
coloring for a smaller $k$ than the number of available registers, which
potentially means more spills by itself. On architectures like x86-64, where
some instructions only work with certain registers there is another difficulty
in choosing the on the side registers. If the registers needed by the
constrained instructions are put off the side, they would prevent any
allocation. But keeping them in the regular allocatable set would mean that
they won't be available for handling the spills of the values constrained to
such registers, the off the side registers would have to be used to somehow swap
the values with the needed registers.

\secc Reduction (to another NP-complete problem and using a solver)

ILP, IBQP

\secc SSA register allocation


\bibchap
\usebib/s (iso690) vlasami6-dip

\bye

This sequence simulates \"three address code" (see TODO) and the second instruction
is in fact what we started with to show use of spilled pseudoregisters.


As we have discussed in TODO, most instructions on
the x86-64 use the "two address code", where one of the operands is also the
destination for the result. Generally, three address code (where operations have
two operands and one destination that may or may not coincide with one of the
operands), are nicer from the perspective of the compiler---it is (at least in
principle, or while we are operating with pseudoregisters) non-destructive.





Coalescing vs live range splitting.



%The important takeaway is, that during register allocation by
%graph coloring, there are multiple potential causes for the graph becoming
%uncolorable, in any algorithm:
%
%\begitems
%* The graph needs more than $k$ colors to be colored.
%* The algorithm is too inexact to find a coloring.
%\enditems

needs to be noted that
more exact algorithm are necessarily able to find colorings even for graphs
which other algorithms would deem uncolorable. Briggs' approach is a 

The
interference graph has to change to 

\seccc Test

test




CHAITIN RECKLESS COALESCING

BRIGGS CONSERVATIVE COALESCING

GEORGE APPEL ITERATED REGISTER COALESCING



Since graph coloring can fail not only due to the graphs being uncolorable due
to interferences of precolored nodes, but also due to the graph having simply
needing more registers to be colored, we 

Since nodes corresponding to physical registers have a color associated with
them
Machine instruction constraints and calling conventions can be modelled bmachine constraints apply to {\em physical}
registers and by also adding them as nodes the interference graph, we can add
interferences between physical and virtual registers. This allows us to model
all usual constraints:

\begitems
* {\em Instructions allowing only specific input registers.} We 
\enditems

Graph coloring can fail not only because the graph's chromatic number is too
high, but also just because the particular graph coloring algorithm at hand is
{\em unable} to find a coloring.

so such
graphs (programs) need to be changed and graph coloring needs to be attempted
again. The changes






Zkratky:

DAG
JIT
